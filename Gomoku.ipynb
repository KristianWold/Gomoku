{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gomoku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import numpy as np\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# Set fontsizes in figures\n",
    "#params = {'legend.fontsize': 'large',\n",
    "#          'axes.labelsize': 'large',\n",
    "#          'axes.titlesize': 'large',\n",
    "#          'xtick.labelsize': 'large',\n",
    "#          'ytick.labelsize': 'large',\n",
    "#          'legend.fontsize': 'large',\n",
    "#          'legend.handlelength': 2}\n",
    "#plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Game:\n",
    "    \n",
    "    def __init__(self, agents, N, visualize = False):\n",
    "        \n",
    "        self.agents = agents\n",
    "        self.N = N\n",
    "        self.visualize = visualize\n",
    "        \n",
    "        if self.visualize == True:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(111)\n",
    "            self.fig.show()\n",
    "            self.fig.canvas.draw()\n",
    "            \n",
    "            self.state = np.zeros((2,self.N,self.N), dtype = int)\n",
    "            self.turn = 0\n",
    "            self.X = [[np.copy(self.state)],[]]\n",
    "            self.y = [[],[]]\n",
    "\n",
    "    def count_in_a_row(self, i, move, x, y):\n",
    "        \n",
    "        in_a_row = 1\n",
    "        counting = True\n",
    "        j, k = move\n",
    "        \n",
    "        while(counting and -1 < j+x < 15 and -1 < k+y < 15):\n",
    "            if self.state[i, j+x, k+y] == 1:\n",
    "                in_a_row += 1\n",
    "                j += x\n",
    "                k += y\n",
    "            else:\n",
    "                counting = False\n",
    "        \n",
    "        counting = True\n",
    "        j, k = move\n",
    "        \n",
    "        while(counting and -1 < j-x < 15 and -1 < k-y < 15):\n",
    "            if self.state[i, j-x, k-y] == 1:\n",
    "                in_a_row += 1\n",
    "                j -= x\n",
    "                k -= y\n",
    "            else:\n",
    "                counting = False\n",
    "            \n",
    "        return in_a_row\n",
    "    \n",
    "\n",
    "    def check_win(self, i, move):\n",
    "        j, k = move\n",
    "        \n",
    "        if self.count_in_a_row(i, move, 1, 0) >= 5:\n",
    "            return True\n",
    "            \n",
    "        if self.count_in_a_row(i, move, 0, 1) >= 5:\n",
    "            return True\n",
    "        \n",
    "        if self.count_in_a_row(i, move, 1, 1) >= 5:\n",
    "            return True\n",
    "            \n",
    "        if self.count_in_a_row(i, move, 1, -1) >= 5:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "            \n",
    "        \n",
    "    def next_move(self):\n",
    "        i = self.turn % 2\n",
    "        \n",
    "        if i == 0:\n",
    "            move = self.agents[i](self.state)\n",
    "        else:\n",
    "            move = self.agents[i](self.state[::-1])\n",
    "\n",
    "        self.X[i].append(np.copy(self.state))\n",
    "        self.y[i].append(self.N*move[0] + move[1])\n",
    "            \n",
    "        self.state[i][move] = 1\n",
    "        self.turn += 1\n",
    "        \n",
    "        return self.check_win(i, move)\n",
    "       \n",
    "\n",
    "    def play(self):\n",
    "        self.state = np.zeros((2, 15, 15), dtype = int)\n",
    "        self.turn = 0\n",
    "        self.X = [[],[]]\n",
    "        self.y = [[],[]]\n",
    "        \n",
    "        while(not self.next_move()):\n",
    "            pass\n",
    "        \n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "        \n",
    "     \n",
    "    def plot(self):\n",
    "        player1 = np.where(self.state[0] == 1)\n",
    "        player2 = np.where(self.state[1] == 1)\n",
    "\n",
    "        self.ax.clear()   \n",
    "        self.ax.plot(player1[0]+0.25, player1[1]+0.25, \"ro\")\n",
    "        self.ax.plot(player2[0]+0.25, player2[1]+0.25, \"bo\")\n",
    "        \n",
    "        minorLocator = MultipleLocator(0.5)\n",
    "        self.ax.yaxis.set_minor_locator(minorLocator)\n",
    "        self.ax.xaxis.set_minor_locator(minorLocator)\n",
    "        self.ax.grid(which = 'both')\n",
    "        \n",
    "        self.ax.axis([0, self.N, 0, self.N])\n",
    "        self.fig.canvas.draw()\n",
    "             \n",
    "\n",
    "def user_input(states):\n",
    "    x = int(input())\n",
    "    y = int(input())\n",
    "    return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(2, 15, 15)),\n",
    "    tf.keras.layers.Dense(units=450, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=225, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#plt.ion()\n",
    "def agent(state):\n",
    "    moves = model.predict(state[np.newaxis, :])[0]\n",
    "    \n",
    "    while(True):\n",
    "        move = np.argmax(moves)\n",
    "        if state[0].ravel()[move] == 1 or state[1].ravel()[move] == 1:\n",
    "            moves[move] = 0\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    move = np.unravel_index(move, (15, 15))\n",
    "    return move\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def loss(model, X_win, y_win):\n",
    "    y_pred = model.predict(X_win)\n",
    "    return tf.losses.MSE(y_pred, y_win)\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.ADAM(learning_rate=0.01)\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "loss_value, grads = grad(model, X_win, y_win)\n",
    "\n",
    "\n",
    "\n",
    "game = Game([agent, agent], 15)\n",
    "\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    game.play()\n",
    "    \n",
    "\n",
    "#while not game.next_move():\n",
    "#    game.plot()\n",
    "    \n",
    "#game.plot()    \n",
    "#if game.turn % 2 == 1:\n",
    "#    print(\"Red wins!\")\n",
    "#else:\n",
    "#    print(\"Blue wins!\")\n",
    "\n",
    "#print(len(game.y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(game.y[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
